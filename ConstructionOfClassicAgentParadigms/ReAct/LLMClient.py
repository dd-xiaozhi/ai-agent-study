import os
from typing import Dict, List
from openai import OpenAI


class LLMClient:
    """
    LLMå®¢æˆ·ç«¯, åŸºäº OpenAI API å°è£…
    """
    def __init__(self, model: str, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        if not model:
            raise ValueError("model is required")
        self.model = model
        self.apiKey = apiKey or os.getenv("OPENAI_API_KEY")
        self.baseUrl = baseUrl or os.getenv("OPENAI_API_BASE_URL")
        self.timeout = timeout or 30

        if not all([self.model, self.apiKey, self.baseUrl]):
            raise ValueError("æ¨¡å‹ã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨ç¯å¢ƒå˜é‡ä¸­å®šä¹‰ã€‚")

        self.client = OpenAI(
            api_key=self.apiKey,
            base_url=self.baseUrl,
            timeout=self.timeout
        )

    def generate(self,
                 message: List[Dict[str, str]],
                 temperature: float = 0,
                 stream: bool = True
                 ) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹ï¼Œç”Ÿæˆå›ç­”
        """
        print(f"================ ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹ ================")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=message,
                temperature=temperature,
                stream=stream
            )

            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)
            # è¾“å‡ºç»“æŸåæ¢è¡Œ
            print()
            return "".join(collected_content)
        except Exception as e:
            print(f"âŒ è°ƒç”¨å¤§æ¨¡å‹å¤±è´¥: {e}")
            return None


if __name__ == "__main__":
    try:
        llmClient = LLMClient(model="deepseek-chat")

        exampleMessages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª python ä»£ç ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ç”Ÿæˆ python ä»£ç ã€‚"},
            {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
        ]

        print("--- è°ƒç”¨LLM ---")
        responseText = llmClient.generate(exampleMessages, stream=True)
        if responseText:
            print("\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---")
            print(responseText)

    except ValueError as e:
        print(e)
